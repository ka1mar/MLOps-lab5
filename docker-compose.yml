version: '3.8'

services:
  spark-master:
    image: bitnami/spark:3.5.1
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_DAEMON_MEMORY=4g
    volumes:
      - ./data:/app/data


  spark-worker:
    image: bitnami/spark:3.5.1
    container_name: spark-worker
    ports:
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4g
    depends_on:
      - spark-master
    volumes:
      - ./data:/app/data


  clustering-app:
    image: bitnami/spark:3.5.1
    container_name: clustering-app
    ports:
      - "4040:4040"
    depends_on:
      - spark-master
    volumes:
      - ./data:/app/data
      - ./scripts:/app/scripts
    command: >
      /bin/bash -c "pip install numpy && \
      spark-submit 
      --master spark://spark-master:7077 
      --executor-memory 4g 
      /app/scripts/clustering.py 
      -i /app/data/en.openfoodfacts.org.products.csv 
      -o /app/data/cluster_results 
      --max_missing 0.3 
      --min_unique 0.3 
      -v"

  # word-count-runner:
  #   image: bitnami/spark:3.5.1
  #   container_name: word-count-runner
  #   depends_on:
  #     - spark-master
  #   volumes:
  #     - ./data:/app/data
  #     - ./scripts:/app/scripts
  #   command: >
  #     /bin/bash -c "spark-submit 
  #     --master spark://spark-master:7077 
  #     /app/scripts/word_count.py 
  #     -i /app/data/sample_text.txt 
  #     -o /app/data/output"